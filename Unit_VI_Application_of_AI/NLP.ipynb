{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPnRktHlnRSAObCoqiaC8m7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lXnrDoj8D3Qm"},"outputs":[],"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer, WordNetLemmatizer"]},{"cell_type":"code","source":["nltk.download(\"punkt\")\n","nltk.download(\"stopwords\")\n","nltk.download(\"wordnet\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8oXOF7cAEY4y","executionInfo":{"status":"ok","timestamp":1731342749394,"user_tz":-345,"elapsed":935,"user":{"displayName":"Subikshya Acharya","userId":"17717785610902897231"}},"outputId":"ac33212e-b9e9-4859-ea3e-820a28b04589"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["text = \"Natural Language Processing is a fascinating field of AI that focuses on understanding human language.\"\n","\n","words = word_tokenize(text)\n","print(\"Words:\", words)\n","\n","stop_words = set(stopwords.words(\"english\"))\n","filtered_words = [word for word in words if word.isalnum() and word.lower() not in stop_words]\n","print(\"Filtered Words (Stopwords Removed):\", filtered_words)\n","\n","stemmer = PorterStemmer()\n","stemmed_words = [stemmer.stem(word) for word in filtered_words]\n","print(\"Stemmed Words:\", stemmed_words)\n","\n","lemmatizer = WordNetLemmatizer()\n","lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n","print(\"Lemmatized Words:\", lemmatized_words)"],"metadata":{"id":"500gbPoOEeNc","executionInfo":{"status":"ok","timestamp":1731342774522,"user_tz":-345,"elapsed":1966,"user":{"displayName":"Subikshya Acharya","userId":"17717785610902897231"}},"outputId":"f031616c-e81f-43bf-e184-5d2b4cd62538","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Words: ['Natural', 'Language', 'Processing', 'is', 'a', 'fascinating', 'field', 'of', 'AI', 'that', 'focuses', 'on', 'understanding', 'human', 'language', '.']\n","Filtered Words (Stopwords Removed): ['Natural', 'Language', 'Processing', 'fascinating', 'field', 'AI', 'focuses', 'understanding', 'human', 'language']\n","Stemmed Words: ['natur', 'languag', 'process', 'fascin', 'field', 'ai', 'focus', 'understand', 'human', 'languag']\n","Lemmatized Words: ['Natural', 'Language', 'Processing', 'fascinating', 'field', 'AI', 'focus', 'understanding', 'human', 'language']\n"]}]}]}